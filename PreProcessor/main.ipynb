{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af479dbb-6af5-456c-ab3f-b1bc8160a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a5d4332-2574-4193-b966-e87e2b83e950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'male', 1: 'female'},\n",
       " {'male': 0, 'female': 1},\n",
       " {0: 'white', 1: 'black', 2: 'asian', 3: 'hispanic', 4: 'middle eastern'},\n",
       " {'white': 0, 'black': 1, 'asian': 2, 'hispanic': 3, 'middle eastern': 4})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('merged_feret_train.csv')\n",
    "generated_df = pd.read_csv('feret_generated.csv')\n",
    "df = pd.concat([df, generated_df], ignore_index=True)\n",
    "\n",
    "DATA_DIR = \"./colored/\"\n",
    "TRAIN_TEST_SPLIT = 0.7\n",
    "IM_WIDTH = 100\n",
    "IM_HEIGHT = 100\n",
    "ID_GENDER_MAP = {0: 'male', 1: 'female'}\n",
    "GENDER_ID_MAP = dict((g, i) for i, g in ID_GENDER_MAP.items())\n",
    "ID_RACE_MAP = {0: 'white', 1: 'black', 2: 'asian', 3: 'hispanic', 4: 'middle eastern'}\n",
    "RACE_ID_MAP = dict((r, i) for i, r in ID_RACE_MAP.items())\n",
    "\n",
    "ID_GENDER_MAP, GENDER_ID_MAP, ID_RACE_MAP, RACE_ID_MAP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0af70653-6bae-40f3-8480-b6edfd551921",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('merged_feret_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c01e71c3-3db5-4d7e-8c44-7279e9685a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(661, 284)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.random.permutation(len(df))\n",
    "train_up_to = int(len(df))\n",
    "train_idx = p[:train_up_to]\n",
    "\n",
    "# split train_idx further into training and validation set\n",
    "train_up_to = int(train_up_to * 0.7)\n",
    "train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\n",
    "\n",
    "df['gender_id'] = df['gender'].map(lambda gender: gender)\n",
    "df['race_id'] = df['race'].map(lambda race: race)\n",
    "\n",
    "len(train_idx), len(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b45b8525-2942-4e02-bb1e-cb7100a4880d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>is_generated</th>\n",
       "      <th>gender_id</th>\n",
       "      <th>race_id</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00823_940307_fa_a_converted_final.png</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>./colored/00823_940307_fa_a_converted_final.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00855_940307_fa_converted_final.png</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>./colored/00855_940307_fa_converted_final.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00869_940307_fa_converted_final.png</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>./colored/00869_940307_fa_converted_final.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00912_960530_fa_converted_final.png</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>./colored/00912_960530_fa_converted_final.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00926_960627_fa_converted_final.png</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>./colored/00926_960627_fa_converted_final.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>1_4_20231227211914296737.png</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>./feret_all/1_4_20231227211914296737.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>1_4_20231227211945054664.png</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>./feret_all/1_4_20231227211945054664.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>1_4_20231227212007592997.png</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>./feret_all/1_4_20231227212007592997.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>1_4_20231227212143839029.png</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>./feret_all/1_4_20231227212143839029.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>1_4_20231227212235429078.png</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>./feret_all/1_4_20231227212235429078.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>945 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  filename  gender  race is_generated  \\\n",
       "0    00823_940307_fa_a_converted_final.png       1     4          NaN   \n",
       "1      00855_940307_fa_converted_final.png       0     4          NaN   \n",
       "2      00869_940307_fa_converted_final.png       0     4          NaN   \n",
       "3      00912_960530_fa_converted_final.png       0     4          NaN   \n",
       "4      00926_960627_fa_converted_final.png       0     4          NaN   \n",
       "..                                     ...     ...   ...          ...   \n",
       "940           1_4_20231227211914296737.png       1     4         True   \n",
       "941           1_4_20231227211945054664.png       1     4         True   \n",
       "942           1_4_20231227212007592997.png       1     4         True   \n",
       "943           1_4_20231227212143839029.png       1     4         True   \n",
       "944           1_4_20231227212235429078.png       1     4         True   \n",
       "\n",
       "     gender_id  race_id                                             file  \n",
       "0            1        4  ./colored/00823_940307_fa_a_converted_final.png  \n",
       "1            0        4    ./colored/00855_940307_fa_converted_final.png  \n",
       "2            0        4    ./colored/00869_940307_fa_converted_final.png  \n",
       "3            0        4    ./colored/00912_960530_fa_converted_final.png  \n",
       "4            0        4    ./colored/00926_960627_fa_converted_final.png  \n",
       "..         ...      ...                                              ...  \n",
       "940          1        4         ./feret_all/1_4_20231227211914296737.png  \n",
       "941          1        4         ./feret_all/1_4_20231227211945054664.png  \n",
       "942          1        4         ./feret_all/1_4_20231227212007592997.png  \n",
       "943          1        4         ./feret_all/1_4_20231227212143839029.png  \n",
       "944          1        4         ./feret_all/1_4_20231227212235429078.png  \n",
       "\n",
       "[945 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = \"./colored/\"\n",
    "generation_path = \"./feret_all/\"\n",
    "df['file'] = df['filename'].apply(lambda x: os.path.join(root_path if \"final\" in x else generation_path, x))\n",
    "test_df['file'] = test_df['filename'].apply(lambda x: os.path.join(root_path, x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "140e2240-5596-4e87-9409-90c401938c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "\n",
    "def get_data_generator(df, indices, for_training, batch_size=16):\n",
    "    images, races, genders = [], [], []\n",
    "    while True:\n",
    "        for i in indices:\n",
    "            r = df.iloc[i]\n",
    "            file, race, gender = r['file'], r['race_id'], r['gender_id']\n",
    "            im = Image.open(file)\n",
    "            im = im.resize((IM_WIDTH, IM_HEIGHT))\n",
    "            im = np.array(im)\n",
    "            images.append(im)\n",
    "            races.append(to_categorical(race, len(RACE_ID_MAP)))\n",
    "            genders.append(to_categorical(gender, 2))\n",
    "            if len(images) >= batch_size:\n",
    "                yield np.array(images), [np.array(races), np.array(genders)]\n",
    "                images, races, genders = [], [], []\n",
    "        if not for_training:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1522a0b4-3a1a-4816-ac76-668e6e0b8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, BatchNormalization, Conv2D, MaxPool2D, GlobalMaxPool2D, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model\n",
    "\n",
    "def conv_block(inp, filters=32, bn=True, pool=True):\n",
    "    _ = Conv2D(filters=filters, kernel_size=3, activation='relu')(inp)\n",
    "    if bn:\n",
    "        _ = BatchNormalization()(_)\n",
    "    if pool:\n",
    "        _ = MaxPool2D()(_)\n",
    "    return _\n",
    "\n",
    "input_layer = Input(shape=(IM_HEIGHT, IM_WIDTH, 3))\n",
    "_ = conv_block(input_layer, filters=32, bn=False, pool=False)\n",
    "_ = conv_block(_, filters=32*2)\n",
    "_ = conv_block(_, filters=32*3)\n",
    "_ = conv_block(_, filters=32*4)\n",
    "_ = conv_block(_, filters=32*5)\n",
    "_ = conv_block(_, filters=32*6)\n",
    "bottleneck = GlobalMaxPool2D()(_)\n",
    "\n",
    "\n",
    "# for race prediction\n",
    "_ = Dense(units=1024, activation='relu')(bottleneck)\n",
    "race_output = Dense(units=len(RACE_ID_MAP), activation='softmax', name='race_output')(_)\n",
    "\n",
    "# for gender prediction\n",
    "_ = Dense(units=256, activation='relu')(bottleneck)\n",
    "gender_output = Dense(units=len(GENDER_ID_MAP), activation='softmax', name='gender_output')(_)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[race_output, gender_output])\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss={'race_output': 'categorical_crossentropy', 'gender_output': 'categorical_crossentropy'},\n",
    "              loss_weights={'race_output': 1.5, 'gender_output': 1.},\n",
    "              metrics={'race_output': 'accuracy', 'gender_output': 'accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccecaeb4-8dfa-41d4-9b39-960c383e3dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21563/2629488138.py:12: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_gen,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "10/10 [==============================] - ETA: 0s - loss: 3.2183 - race_output_loss: 1.6144 - gender_output_loss: 0.7967 - race_output_accuracy: 0.5719 - gender_output_accuracy: 0.7078INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 11s 1s/step - loss: 3.2183 - race_output_loss: 1.6144 - gender_output_loss: 0.7967 - race_output_accuracy: 0.5719 - gender_output_accuracy: 0.7078 - val_loss: 54.5455 - val_race_output_loss: 31.0568 - val_gender_output_loss: 7.9603 - val_race_output_accuracy: 0.0664 - val_gender_output_accuracy: 0.4727\n",
      "Epoch 2/16\n",
      "10/10 [==============================] - ETA: 0s - loss: 2.2380 - race_output_loss: 1.1672 - gender_output_loss: 0.4871 - race_output_accuracy: 0.6203 - gender_output_accuracy: 0.7844INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 878ms/step - loss: 2.2380 - race_output_loss: 1.1672 - gender_output_loss: 0.4871 - race_output_accuracy: 0.6203 - gender_output_accuracy: 0.7844 - val_loss: 15.9882 - val_race_output_loss: 9.6042 - val_gender_output_loss: 1.5819 - val_race_output_accuracy: 0.0586 - val_gender_output_accuracy: 0.5391\n",
      "Epoch 3/16\n",
      "10/10 [==============================] - ETA: 0s - loss: 1.8083 - race_output_loss: 0.9267 - gender_output_loss: 0.4183 - race_output_accuracy: 0.6734 - gender_output_accuracy: 0.8250INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 857ms/step - loss: 1.8083 - race_output_loss: 0.9267 - gender_output_loss: 0.4183 - race_output_accuracy: 0.6734 - gender_output_accuracy: 0.8250 - val_loss: 20.7553 - val_race_output_loss: 12.0815 - val_gender_output_loss: 2.6331 - val_race_output_accuracy: 0.0859 - val_gender_output_accuracy: 0.5352\n",
      "Epoch 4/16\n",
      "10/10 [==============================] - ETA: 0s - loss: 1.5100 - race_output_loss: 0.7866 - gender_output_loss: 0.3301 - race_output_accuracy: 0.6812 - gender_output_accuracy: 0.8500INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 880ms/step - loss: 1.5100 - race_output_loss: 0.7866 - gender_output_loss: 0.3301 - race_output_accuracy: 0.6812 - gender_output_accuracy: 0.8500 - val_loss: 30.5195 - val_race_output_loss: 16.0451 - val_gender_output_loss: 6.4519 - val_race_output_accuracy: 0.0859 - val_gender_output_accuracy: 0.5273\n",
      "Epoch 5/16\n",
      "10/10 [==============================] - ETA: 0s - loss: 1.3332 - race_output_loss: 0.6797 - gender_output_loss: 0.3136 - race_output_accuracy: 0.7500 - gender_output_accuracy: 0.8750INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 857ms/step - loss: 1.3332 - race_output_loss: 0.6797 - gender_output_loss: 0.3136 - race_output_accuracy: 0.7500 - gender_output_accuracy: 0.8750 - val_loss: 14.1792 - val_race_output_loss: 8.5436 - val_gender_output_loss: 1.3638 - val_race_output_accuracy: 0.0977 - val_gender_output_accuracy: 0.5273\n",
      "Epoch 6/16\n",
      "10/10 [==============================] - ETA: 0s - loss: 1.1001 - race_output_loss: 0.5652 - gender_output_loss: 0.2523 - race_output_accuracy: 0.7859 - gender_output_accuracy: 0.8875INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 886ms/step - loss: 1.1001 - race_output_loss: 0.5652 - gender_output_loss: 0.2523 - race_output_accuracy: 0.7859 - gender_output_accuracy: 0.8875 - val_loss: 14.8845 - val_race_output_loss: 9.2983 - val_gender_output_loss: 0.9370 - val_race_output_accuracy: 0.0703 - val_gender_output_accuracy: 0.5039\n",
      "Epoch 7/16\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.9020 - race_output_loss: 0.4820 - gender_output_loss: 0.1789 - race_output_accuracy: 0.8188 - gender_output_accuracy: 0.9281INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 860ms/step - loss: 0.9020 - race_output_loss: 0.4820 - gender_output_loss: 0.1789 - race_output_accuracy: 0.8188 - gender_output_accuracy: 0.9281 - val_loss: 11.2642 - val_race_output_loss: 6.5398 - val_gender_output_loss: 1.4544 - val_race_output_accuracy: 0.0625 - val_gender_output_accuracy: 0.5195\n",
      "Epoch 8/16\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7806 - race_output_loss: 0.4083 - gender_output_loss: 0.1681 - race_output_accuracy: 0.8453 - gender_output_accuracy: 0.9359INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 859ms/step - loss: 0.7806 - race_output_loss: 0.4083 - gender_output_loss: 0.1681 - race_output_accuracy: 0.8453 - gender_output_accuracy: 0.9359 - val_loss: 8.5169 - val_race_output_loss: 5.1033 - val_gender_output_loss: 0.8620 - val_race_output_accuracy: 0.1133 - val_gender_output_accuracy: 0.5586\n",
      "Epoch 9/16\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5590 - race_output_loss: 0.2360 - gender_output_loss: 0.2051 - race_output_accuracy: 0.9234 - gender_output_accuracy: 0.9125INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 883ms/step - loss: 0.5590 - race_output_loss: 0.2360 - gender_output_loss: 0.2051 - race_output_accuracy: 0.9234 - gender_output_accuracy: 0.9125 - val_loss: 4.5466 - val_race_output_loss: 2.3756 - val_gender_output_loss: 0.9832 - val_race_output_accuracy: 0.2188 - val_gender_output_accuracy: 0.5078\n",
      "Epoch 10/16\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3666 - race_output_loss: 0.1713 - gender_output_loss: 0.1096 - race_output_accuracy: 0.9469 - gender_output_accuracy: 0.9656INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 851ms/step - loss: 0.3666 - race_output_loss: 0.1713 - gender_output_loss: 0.1096 - race_output_accuracy: 0.9469 - gender_output_accuracy: 0.9656 - val_loss: 7.9251 - val_race_output_loss: 4.3001 - val_gender_output_loss: 1.4749 - val_race_output_accuracy: 0.1484 - val_gender_output_accuracy: 0.4922\n",
      "Epoch 11/16\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3875 - race_output_loss: 0.1812 - gender_output_loss: 0.1157 - race_output_accuracy: 0.9406 - gender_output_accuracy: 0.9578INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 881ms/step - loss: 0.3875 - race_output_loss: 0.1812 - gender_output_loss: 0.1157 - race_output_accuracy: 0.9406 - gender_output_accuracy: 0.9578 - val_loss: 4.6912 - val_race_output_loss: 2.3928 - val_gender_output_loss: 1.1019 - val_race_output_accuracy: 0.2891 - val_gender_output_accuracy: 0.5195\n",
      "Epoch 12/16\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5021 - race_output_loss: 0.2770 - gender_output_loss: 0.0867 - race_output_accuracy: 0.9141 - gender_output_accuracy: 0.9703INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 850ms/step - loss: 0.5021 - race_output_loss: 0.2770 - gender_output_loss: 0.0867 - race_output_accuracy: 0.9141 - gender_output_accuracy: 0.9703 - val_loss: 9.9333 - val_race_output_loss: 5.8781 - val_gender_output_loss: 1.1161 - val_race_output_accuracy: 0.1094 - val_gender_output_accuracy: 0.5234\n",
      "Epoch 13/16\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3433 - race_output_loss: 0.1611 - gender_output_loss: 0.1017 - race_output_accuracy: 0.9391 - gender_output_accuracy: 0.9641INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 844ms/step - loss: 0.3433 - race_output_loss: 0.1611 - gender_output_loss: 0.1017 - race_output_accuracy: 0.9391 - gender_output_accuracy: 0.9641 - val_loss: 5.9231 - val_race_output_loss: 3.3434 - val_gender_output_loss: 0.9080 - val_race_output_accuracy: 0.2109 - val_gender_output_accuracy: 0.6328\n",
      "Epoch 14/16\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1635 - race_output_loss: 0.0762 - gender_output_loss: 0.0491 - race_output_accuracy: 0.9734 - gender_output_accuracy: 0.9859INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 880ms/step - loss: 0.1635 - race_output_loss: 0.0762 - gender_output_loss: 0.0491 - race_output_accuracy: 0.9734 - gender_output_accuracy: 0.9859 - val_loss: 2.2051 - val_race_output_loss: 1.1170 - val_gender_output_loss: 0.5296 - val_race_output_accuracy: 0.6484 - val_gender_output_accuracy: 0.7969\n",
      "Epoch 15/16\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1795 - race_output_loss: 0.0861 - gender_output_loss: 0.0504 - race_output_accuracy: 0.9734 - gender_output_accuracy: 0.9766"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 64\n",
    "valid_batch_size = 64\n",
    "train_gen = get_data_generator(df, train_idx, for_training=True, batch_size=batch_size)\n",
    "valid_gen = get_data_generator(df, valid_idx, for_training=True, batch_size=valid_batch_size)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"./model_checkpoint\", monitor='val_loss')\n",
    "]\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=len(train_idx)//batch_size,\n",
    "                    epochs=16,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=valid_gen,\n",
    "                    validation_steps=len(valid_idx)//valid_batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ca9c3-dd38-4f57-af2c-07aac0b863f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  plot_train_history(history):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    axes[0].plot(history.history['race_output_accuracy'], label='Race Train accuracy')\n",
    "    axes[0].plot(history.history['val_race_output_accuracy'], label='Race Val accuracy')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    axes[1].plot(history.history['gender_output_accuracy'], label='Gender Train accuracy')\n",
    "    axes[1].plot(history.history['val_gender_output_accuracy'], label='Gener Val accuracy')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].legend()\n",
    "\n",
    "\n",
    "    axes[2].plot(history.history['loss'], label='Training loss')\n",
    "    axes[2].plot(history.history['val_loss'], label='Validation loss')\n",
    "    axes[2].set_xlabel('Epochs')\n",
    "    axes[2].legend()\n",
    "\n",
    "plot_train_history(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e740d28-99bf-4745-a45e-d9c07411cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_t = np.random.permutation(len(test_df))\n",
    "test_index = p_t[:]\n",
    "len(test_index)\n",
    "test_df['gender_id'] = test_df['gender'].map(lambda gender: gender)\n",
    "test_df['race_id'] = test_df['race'].map(lambda race: race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cfa753-9125-4df6-a444-0f17d2e9b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = get_data_generator(test_df, test_index, for_training=False, batch_size=128)\n",
    "dict(zip(model.metrics_names, model.evaluate_generator(test_gen, steps=len(test_index)//128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe64c41-4d21-4133-b60d-dfdf215200ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = get_data_generator(test_df, test_index, for_training=False, batch_size=128)\n",
    "x_test, (race_true, gender_true)= next(test_gen)\n",
    "race_pred, gender_pred = model.predict_on_batch(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6027adc-187c-41d7-9184-510fe75ab29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8cba5a-9595-4a76-9826-085d9b7be803",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_true, gender_true = race_true.argmax(axis=-1), gender_true.argmax(axis=-1)\n",
    "race_pred, gender_pred = race_pred.argmax(axis=-1), gender_pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef481cf-8e01-46db-8eff-54ba92f8f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification report for race\")\n",
    "print(classification_report(race_true, race_pred))\n",
    "\n",
    "print(\"\\nClassification report for gender\")\n",
    "print(classification_report(gender_true, gender_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d5bcb5-13c7-41ed-babf-640b8ff11eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
